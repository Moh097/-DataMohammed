---
title: "Data"
author: "masri"
date: "2023-08-06"
output: html_document
---

A code chunk only for libraries.
```{r}


```

Take only specific columns after we extracted only the desired countries. 7 Wave
```{r}

# List of desired countries
desired_countries <- c("JOR", "IRQ", "TUN", "MOR", "EGY", "LEB", "LIB")

# Filter the dataset to include only the desired countries
Wave_7_selected <- subset(Wave_7, C_COW_ALPHA %in% desired_countries, select = c("C_COW_ALPHA", "Q46",
                                                                "Q47", "Q48", "Q49",
                                             "Q50", "Q57", "Q209", "Q210", "Q211", "Q212",
                                             "Q213",
                                             "Q215", "Q218", "Q219", "Q220", "Q173",
                                             "Q262", "Q260", "Q279"))

```

Take only specific columns after we extracted only the desired countries. 6 Wave
```{r}
# List of desired countries
desired_countries <- c("JOR", "IRQ", "TUN", "MOR", "EGY", "LEB", "LBY")

# Filter the dataset to include only the desired countries
Wave_6_selected <- subset(Wave_6, C_COW_ALPHA %in% desired_countries, select = c("C_COW_ALPHA", "V10", "V11", "V55", "V23",
                                             "V59", "V24", "V85", "V86", "V87", "V88",
                                             "V147","V242", "V240", "V229"))

```

naming the attributes with meaningful names. 7 Wave
```{r}
library(dplyr)
Wave_7_renamed <- Wave_7_selected %>%
   rename(happiness = Q46, free_choice = Q48, health = Q47, life_satis = Q49,
          financial_satis = Q50, gen_trust = Q57,
          sign_pet = Q209, join_boycott = Q210,
          attend_demo = Q211, join_strike = Q212, donate = Q213, enc_poli = Q215, 
          sign_pet_onli = Q218, enc_poli_onli = Q219, org_poli_onli = Q220,
          religiosity = Q173, age = Q262, gender = Q260, employment = Q279 , 
          country = C_COW_ALPHA)
          
```

naming the attributes with meaningful names. 6 Wave
```{r}
library(dplyr)
Wave_6_renamed <- Wave_6_selected %>%
   rename(happiness = V10, health = V11, free_choice = V55, life_satis = V23, 
          financial_satis = V59, gen_trust = V24, sign_pet = V85, join_boycott = V86,
          attend_demo = V87,
          join_strike = V88, religiosity = V147, age = V242, gender = V240,
          employment = V229, country = C_COW_ALPHA)
          
```

cleaning the dataset. 7 Wave
```{r}
for (col in names(Wave_7_renamed)) {
  Wave_7_renamed[[col]][Wave_7_renamed[[col]] %in% 
  c(-1, -2, -4, -5)] <- NA
}
Wave_7_renamed$health[Wave_7_renamed$health == 5] <- 4


```

cleaning the dataset. 6 Wave
```{r}
for (col in names(Wave_6_renamed)) {
  Wave_6_renamed[[col]][Wave_6_renamed[[col]] %in% 
  c(-1, -2, -4, -5)] <- NA
}
```

merge the two data sets.
```{r}
# Load required libraries
library(dplyr)

# Create a mapping to align country codes
country_mapping <- data.frame(original_country = c('LIB'), mapped_country = c('LBY'))

# Apply the mapping to Wave_6_renamed dataset
Wave_6_renamed <- Wave_6_renamed %>%
  left_join(country_mapping, by = c("country" = "original_country")) %>%
  mutate(country = coalesce(mapped_country, country)) %>%
  select(-mapped_country)

# Merge the datasets (Wave_6_renamed and Wave_7_renamed)
merged_data <- bind_rows(Wave_6_renamed, Wave_7_renamed)

# Remove unwanted columns
merged_data <- merged_data[, !(names(merged_data) %in% c("org_poli_onli", "enc_poli_onli", "sign_pet_onli", "donate", "enc_poli"))]
unique(merged_data$country)

```

recoding the variables by flipping from ascending to descending.
```{r}

library(dplyr)

# Define the recoding rules
recoding_rules_happiness <- c(
  "1" = "4",
  "2" = "3",
  "3" = "2",
  "4" = "1"
)

recoding_rules_health <- c(
  "1" = "4",
  "2" = "3",
  "3" = "2",
  "4" = "1"
)


recoding_rules <- c(
  "1" = "3",
  "2" = "2",
  "3" = "1"
)

# Apply the recoding to the specified variables in wave_7 dataset
merged_data_recoded <- merged_data %>%
  mutate(
    sign_pet = recode(sign_pet, !!!recoding_rules),
    join_boycott = recode(join_boycott, !!!recoding_rules),
    attend_demo = recode(attend_demo, !!!recoding_rules),
    join_strike = recode(join_strike, !!!recoding_rules),
    health = recode(health, !!!recoding_rules_health),
    happiness = recode(happiness, !!!recoding_rules_happiness)
  )

```

taking the VAR value from wgidataset and store it in 'filtered_data'
```{r}
# Load dplyr package
library(dplyr)

# Original dataset is wgidataset

# Create a data frame containing the target countries and years
target_data <- data.frame(
  countryname = c("Egypt, Arab Rep.", "Iraq", "Jordan", "Lebanon", "Libya", "Morocco", "Tunisia"),
  year = c(2016, 2016, 2016, 2016, 2017, 2016, 2016)
)

# Merge the original dataset (wgidataset) with target_data on 'countryname' and 'year'
filtered_data <- wgidataset %>%
  inner_join(target_data, by = c("countryname", "year")) %>%
  select(countryname, year, var)  # select only the columns we need

# View the filtered data
print(filtered_data)

```

merge the VAR values with 'merged_data' and call it 'final_dataset'
```{r}
# Load the required library
library(dplyr)

# Create a mapping dataframe for country abbreviations and full names
country_mapping <- data.frame(
  country = c("JOR", "IRQ", "TUN", "MOR", "EGY", "LEB", "LIB"),
  countryname = c("Jordan", "Iraq", "Tunisia", "Morocco", "Egypt, Arab Rep.", "Lebanon", "Libya")
)

# Merge the mapping dataframe with the existing dataset to get full country names
merged_data_with_fullnames <- left_join(merged_data_recoded, country_mapping, by = "country")

# Merge to add the 'var' column from filtered_data
final_dataset <- left_join(merged_data_with_fullnames, filtered_data[, c("countryname", "var")], by = "countryname")

# Optionally, remove the 'countryname' column after the merging
final_dataset$countryname <- NULL

```

making sure of the variables and the VAR values
```{r}
unique_dataset <- final_dataset %>% 
  select(country, var) %>% 
  distinct()

# Print the unique dataset
print(unique_dataset)
names(final_dataset)
```

visualize the missing values for every attibute in the merged data.
```{r}
library(ggplot2)

# Assuming 'merged_data' is your data frame
missing_proportions <- colMeans(is.na(merged_data))
missing_data_df <- data.frame(variable = names(missing_proportions), proportion = missing_proportions)

# Create a bar chart to visualize missing data proportions
ggplot(missing_data_df, aes(x = variable, y = proportion)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Proportion of Missing Data by Variable", x = "Variable", y = "Proportion Missing") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

calculating and printing the propotions of the missing data in the merged data.
```{r}
library(dplyr)
library(writexl)

# Your existing code for summarizing missing proportions
merged_data %>%
  group_by(country) %>%
  summarise(across(
    .cols = everything(),
    .fns = ~ mean(is.na(.x)),
    .names = "{.col}_missing_proportion"
  )) -> missing_proportions

# Specify the file path where you want to save the Excel file
output_path <- "C:/Users/LENOVO/Desktop/DataMohammed/Data/missing_proportion.xlsx"

# Save the summarized data to an Excel file
write_xlsx(missing_proportions, path = output_path)

cat("Excel file saved at:", output_path, "\n")
```

visualize the missing data according to the attributes in merged data using dlookr library.
```{r}
library(dlookr)
plot_na_pareto(merged_data)
plot_na_intersect(merged_data)
```

renaming the data in the data set.
```{r}
library(dplyr)

#=======employment=========================================================================

employment_mapping <- c(
  "1" = "Full time",
  "2" = "Part time",
  "3" = "Self employed",
  "4" = "Retired",
  "5" = "Housewife not otherwise employed",
  "6" = "Student",
  "7" = "Unemployed",
  "null" = "null"
)
#=======join_strike=========================================================================

join_strike_mapping <- c(
  "1" = "Would never do",
  "2" = "Might do",
  "3" = "Have done",
  "null" = "null"
)
#=======attend_demo=========================================================================

attend_demo_mapping <- c(
  "1" = "Would never do",
  "2" = "Might do",
  "3" = "Have done",
  "null" = "null"
)
#=======join_boycott========================================================================

join_boycott_mapping <- c(
  "1" = "Would never do",
  "2" = "Might do",
  "3" = "Have done",
  "null" = "null"
)
#=======sign_pet============================================================================

sign_pet_mapping <- c(
  "1" = "Would never do",
  "2" = "Might do",
  "3" = "Have done",
  "null" = "null"
)
#=======gen_trust===========================================================================

gen_trust_mapping <- c(
  "1" = "Most people can be trusted",
  "2" = "Need to be very careful",
  "null" = "null"
)
#=======financial_satis=====================================================================

financial_satis_mapping <- c(
  "1" = "Dissatisfied",
  "2" = "2",
  "3" = "3",
  "4" = "4",
  "5" = "5",
  "6" = "6",
  "7" = "7",
  "8" = "8",
  "9" = "9",
  "10" = "Satisfied",
  "null" = "null"
)
#=======life_satis==========================================================================

life_satis_mapping <- c(
  "1" = "compeltely dissatisfied",
  "2" = "2",
  "3" = "3",
  "4" = "4",
  "5" = "5",
  "6" = "6",
  "7" = "7",
  "8" = "8",
  "9" = "9",
  "10" = "compeltely Satisfied",
  "null" = "null"
)
#=======health============================================================================

health_mapping <- c(
  "1" = "Poor",
  "2" = "Fair",
  "3" = "Good",
  "4" = "Very good",
  "null" = "null"
)
#=======free_choice=========================================================================

free_choice_mapping <- c(
  "1" = "None at all",
  "2" = "2",
  "3" = "3",
  "4" = "4",
  "5" = "5",
  "6" = "6",
  "7" = "7",
  "8" = "8",
  "9" = "9",
  "10" = "A great deal",
  "null" = "null"
)
#=======happiness===========================================================================

happiness_mapping <- c(
    "1" = "Not at all happy",
    "2" = "Not very happy",
    "3" = "Quite happy",
    "4" = "Very happy",
    "null" = "null"
)
#=======gender===========================================================================

gender_mapping <- c(
  "1" = "Male",
  "2" = "Female",
  "null" = "null"
)

#=======religiosity=========================================================================

religiosity_mapping <- c(
  "1" = "A religious person",
  "2"  = "Not a religious person",
  "3" = "An atheist",
  "null" = "null"
)

merged_renamed <- mutate(final_imputet,
    employment = employment_mapping[as.character(employment)],
    join_strike = join_strike_mapping[as.character(join_strike)],
    attend_demo = attend_demo_mapping[as.character(attend_demo)],
    join_boycott = join_boycott_mapping[as.character(join_boycott)],
    sign_pet = sign_pet_mapping[as.character(sign_pet)],
    gen_trust = gen_trust_mapping[as.character(gen_trust)],
    financial_satis = financial_satis_mapping[as.character(financial_satis)],
    life_satis = life_satis_mapping[as.character(life_satis)],
    health = health_mapping[as.character(health)],
    free_choice = free_choice_mapping[as.character(free_choice)],
    happiness = happiness_mapping[as.character(happiness)],
    gender = gender_mapping[as.character(gender)],
    religiosity = religiosity_mapping[as.character(religiosity)]
)
```

creating a data frame to do iterations and imputation then do the missForest *imputation* method to handle the missing data.
```{r}
library(missRanger)
library(ggplot2)

final_imputet <- data.frame(final_dataset)

final_imputet <- missRanger(
  final_imputet, 
  formula = . ~ . ,
  num.trees = 1000, 
  verbose = 2, 
  seed = 111,  
  returnOOB = T)
```

calculating and printing the propotions of the missing data in the merged data after the imputation.
```{r}
library(dplyr)
library(tidyr)
merged_imputet_rounded %>%
  group_by(country) %>%
  summarise(across(
    .cols = everything(),
    .fns = ~ mean(is.na(.x)),
    .names = "{.col}_missing_proportion"
  )) -> missing_proportions_imputed

# Print the result
print(missing_proportions_imputed)


```

calculate the descriptive statistics across countries.
```{r}
# Load required libraries
library(dplyr)
library(moments)
library(ggplot2)
library(writexl)

# Define the desired countries
desired_countries <- c("JOR", "IRQ", "TUN", "MOR", "EGY", "LEB", "LBY")

# Filter data for desired countries
country_data <- final_dataset %>%
  filter(country %in% desired_countries)

# List of variable names to calculate statistics for
variable_names <- c("happiness", "gen_trust", "health", "free_choice",
                    "life_satis", "financial_satis", "gen_trust",
                    "sign_pet", "join_boycott", "attend_demo",
                    "join_strike", "religiosity", 
                    "age", "gender", "employment", "var")

# Initialize an empty list to store results
results_list <- list()

# Loop through each variable and calculate statistics
for (variable_name in variable_names) {
  variable_stats <- country_data %>%
    summarise(
      variable_name = variable_name,
      mean = mean(!!sym(variable_name), na.rm = TRUE),
      median = median(!!sym(variable_name), na.rm = TRUE),
      mode = as.numeric(names(sort(table(!!sym(variable_name)), decreasing = TRUE)[1])),
      variance = var(!!sym(variable_name), na.rm = TRUE),
      standard_deviation = sd(!!sym(variable_name), na.rm = TRUE),
      range = paste(range(!!sym(variable_name), na.rm = TRUE), collapse = " - "),
      iqr = IQR(!!sym(variable_name), na.rm = TRUE),
      skewness = skewness(!!sym(variable_name), na.rm = TRUE),
      kurtosis = kurtosis(!!sym(variable_name), na.rm = TRUE)
    )
  
  results_list[[variable_name]] <- variable_stats
}

# Combine results into a single data frame
results_df <- bind_rows(results_list)

# Create a bar chart for mean values
mean_bar_chart <- ggplot(results_df, aes(x = variable_name, y = mean)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Mean Values for Different Variables Across Desired Countries",
       x = "Variable", y = "Mean Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the bar chart
print(mean_bar_chart)

# Define the file path for the Excel file
file_path <- "C:/Users/LENOVO/Desktop/DataMohammed/Data/statistics_results.xlsx"

# Write the data frame to the specified Excel file path
write_xlsx(results_df, path = file_path)



```

calculate the descriptive statistics. for each country seperately. 
```{r}
# Load required libraries
# Load required libraries
# Load required libraries
library(dplyr)
library(moments)
library(writexl)
library(openxlsx)

# List of country codes
country_codes <- c("EGY", "IRQ", "JOR", "LEB", "MOR", "TUN", "LIB")

# List of variable names to calculate statistics for
variable_names <- c("happiness", "gen_trust", "health", "free_choice",
                    "life_satis", "financial_satis", "gen_trust",
                    "sign_pet", "join_boycott", "attend_demo",
                    "join_strike", "religiosity", 
                    "age", "gender", "employment")

# Create a new Excel workbook
wb <- createWorkbook()

# Loop through each country
for (country_code in country_codes) {
  country_data <- final_dataset %>%
    filter(country == country_code)  # Filter data for the current country

  # Initialize an empty list to store results for the current country
  country_results <- list()

  # Loop through each variable and calculate statistics for the current country
  for (variable_name in variable_names) {
    variable_stats <- country_data %>%
      summarise(
        variable_name = variable_name,
        mean = mean(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        median = median(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        mode = as.numeric(names(sort(table(!!sym(variable_name)), decreasing = TRUE)[1])),
        variance = var(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        standard_deviation = sd(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        range = paste(range(!!sym(variable_name), na.rm = TRUE), collapse = " - "),  # Add na.rm = TRUE
        iqr = IQR(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        skewness = skewness(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        kurtosis = kurtosis(!!sym(variable_name), na.rm = TRUE)  # Add na.rm = TRUE
      )
    
    # Append variable statistics to the country's results
    country_results[[variable_name]] <- variable_stats
  }

  # Combine results for the current country into a single data frame
  country_results_df <- bind_rows(country_results)

  # Add the country's statistics to a new sheet in the Excel workbook
  addWorksheet(wb, sheetName = country_code)
  writeData(wb, sheet = country_code, x = country_results_df, startCol = 1, startRow = 1)
}

# Save the Excel workbook with statistics for all countries
saveWorkbook(wb, "statistics_all_countries.xlsx")


```

calculate the descriptive statistics across countries. *imputet data*
```{r}
# Load required libraries
library(dplyr)
library(moments)
library(ggplot2)
library(writexl)

# Define the desired countries
desired_countries <- c("JOR", "IRQ", "TUN", "MOR", "EGY", "LEB", "LBY")

# Filter data for desired countries
country_data <- final_imputet %>%
  filter(country %in% desired_countries)

# List of variable names to calculate statistics for
variable_names <- c("happiness", "gen_trust", "health", "free_choice",
                    "life_satis", "financial_satis", "gen_trust",
                    "sign_pet", "join_boycott", "attend_demo",
                    "join_strike", "religiosity", 
                    "age", "gender", "employment", "var")

# Initialize an empty list to store results
results_list <- list()

# Loop through each variable and calculate statistics
for (variable_name in variable_names) {
  variable_stats <- country_data %>%
    summarise(
      variable_name = variable_name,
      mean = mean(!!sym(variable_name), na.rm = TRUE),
      median = median(!!sym(variable_name), na.rm = TRUE),
      mode = as.numeric(names(sort(table(!!sym(variable_name)), decreasing = TRUE)[1])),
      variance = var(!!sym(variable_name), na.rm = TRUE),
      standard_deviation = sd(!!sym(variable_name), na.rm = TRUE),
      range = paste(range(!!sym(variable_name), na.rm = TRUE), collapse = " - "),
      iqr = IQR(!!sym(variable_name), na.rm = TRUE),
      skewness = skewness(!!sym(variable_name), na.rm = TRUE),
      kurtosis = kurtosis(!!sym(variable_name), na.rm = TRUE)
    )
  
  results_list[[variable_name]] <- variable_stats
}

# Combine results into a single data frame
results_df <- bind_rows(results_list)

# Create a bar chart for mean values
mean_bar_chart <- ggplot(results_df, aes(x = variable_name, y = mean)) +
  geom_bar(stat = "identity", fill = "blue") +
  labs(title = "Mean Values for Different Variables Across Desired Countries",
       x = "Variable", y = "Mean Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the bar chart
print(mean_bar_chart)

# Define the file path for the Excel file
file_path <- "C:/Users/LENOVO/Desktop/DataMohammed/Data/statistics_results_imputet.xlsx"

# Write the data frame to the specified Excel file path
write_xlsx(results_df, path = file_path)



```

calculate the descriptive statistics. for each country separately. *imputed data*
```{r}
# Load required libraries
# Load required libraries
# Load required libraries
library(dplyr)
library(moments)
library(writexl)
library(openxlsx)

# List of country codes
country_codes <- c("EGY", "IRQ", "JOR", "LEB", "MOR", "TUN", "LIB")

# List of variable names to calculate statistics for
variable_names <- c("happiness", "gen_trust", "health", "free_choice",
                    "life_satis", "financial_satis", "gen_trust",
                    "sign_pet", "join_boycott", "attend_demo",
                    "join_strike", "religiosity", 
                    "age", "gender", "employment")

# Create a new Excel workbook
wb <- createWorkbook()

# Loop through each country
for (country_code in country_codes) {
  country_data <- final_imputet %>%
    filter(country == country_code)  # Filter data for the current country

  # Initialize an empty list to store results for the current country
  country_results <- list()

  # Loop through each variable and calculate statistics for the current country
  for (variable_name in variable_names) {
    variable_stats <- country_data %>%
      summarise(
        variable_name = variable_name,
        mean = mean(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        median = median(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        mode = as.numeric(names(sort(table(!!sym(variable_name)), decreasing = TRUE)[1])),
        variance = var(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        standard_deviation = sd(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        range = paste(range(!!sym(variable_name), na.rm = TRUE), collapse = " - "),  # Add na.rm = TRUE
        iqr = IQR(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        skewness = skewness(!!sym(variable_name), na.rm = TRUE),  # Add na.rm = TRUE
        kurtosis = kurtosis(!!sym(variable_name), na.rm = TRUE)  # Add na.rm = TRUE
      )
    
    # Append variable statistics to the country's results
    country_results[[variable_name]] <- variable_stats
  }

  # Combine results for the current country into a single data frame
  country_results_df <- bind_rows(country_results)

  # Add the country's statistics to a new sheet in the Excel workbook
  addWorksheet(wb, sheetName = country_code)
  writeData(wb, sheet = country_code, x = country_results_df, startCol = 1, startRow = 1)
}

# Save the Excel workbook with statistics for all countries
saveWorkbook(wb, "statistics_all_countries_imputet.xlsx")


```



visualize the mode for *gen_trust, religiosity, gender, employment* across countries. and save it in one PDF
```{r}
# Load required libraries
library(ggplot2)
library(patchwork)

# List of unique countries
unique_countries <- unique(merged_renamed$country)

# Create a PDF file for all country mode plots
pdf_file <- "all_country_mode_plots.pdf"
pdf(pdf_file, width = 8, height = 6)

# Create a data frame with mode frequencies across all countries
mode_data_all_countries <- data.frame(
  Variable = c("gen_trust", "religiosity", "gender", "employment"),
  Mode = c(
    names(sort(table(merged_renamed$gen_trust), decreasing = TRUE)[1]),
    names(sort(table(merged_renamed$religiosity), decreasing = TRUE)[1]),
    names(sort(table(merged_renamed$gender), decreasing = TRUE)[1]),
    names(sort(table(merged_renamed$employment), decreasing = TRUE)[1])
  ),
  Frequency = c(
    max(table(merged_renamed$gen_trust)),
    max(table(merged_renamed$religiosity)),
    max(table(merged_renamed$gender)),
    max(table(merged_renamed$employment))
  )
)

# Create a bar plot for mode frequencies across all countries
mode_plot_all_countries <- ggplot(mode_data_all_countries, aes(x = Variable, y = Frequency, fill = Mode)) +
  geom_bar(stat = "identity") +
  labs(title = "Mode Frequencies for Categorical Variables Across All Countries",
       x = "Variables",
       y = "Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the mode plot for all countries
print(mode_plot_all_countries)

# Add a page break
cat("\f")

# Loop through each country and generate the mode plot
for (country_code in unique_countries) {
  # Filter data for the specific country
  country_data <- subset(merged_renamed, country == country_code)
  
  # Create a data frame with mode frequencies for the specific country
  mode_data_country <- data.frame(
    Variable = c("gen_trust", "religiosity", "gender", "employment"),
    Mode = c(
      names(sort(table(country_data$gen_trust), decreasing = TRUE)[1]),
      names(sort(table(country_data$religiosity), decreasing = TRUE)[1]),
      names(sort(table(country_data$gender), decreasing = TRUE)[1]),
      names(sort(table(country_data$employment), decreasing = TRUE)[1])
    ),
    Frequency = c(
      max(table(country_data$gen_trust)),
      max(table(country_data$religiosity)),
      max(table(country_data$gender)),
      max(table(country_data$employment))
    )
  )
  
  # Create a bar plot for mode frequencies for the specific country
  mode_plot_country <- ggplot(mode_data_country, aes(x = Variable, y = Frequency, fill = Mode)) +
    geom_bar(stat = "identity") +
    labs(title = paste("Mode Frequencies for Categorical Variables in", country_code),
         x = "Variables",
         y = "Frequency") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  # Print the plot to the PDF
  print(mode_plot_country)
  
  # Add a page break
  cat("\f")
}

# Close the PDF
dev.off()

# Display the combined PDF
system(paste(pdf_file, " &", sep = ""))

```

visualize the median for *happiness, health, sign_pet, join_boycott, attend_demo, join_strike* across countries. and save it in one PDF
```{r}
# Load required libraries
library(ggplot2)

# List of unique countries
unique_countries <- unique(final_imputet$country)

# Specify the variables for which you want to calculate and visualize the median
variables_to_analyze <- c("happiness", "health", "sign_pet", "join_boycott", "attend_demo", "join_strike")

# Create a PDF file for median plots
pdf_file <- "median_plots.pdf"
pdf(pdf_file, width = 8, height = 6)

for (variable_name in variables_to_analyze) {
  median_data_all_countries <- data.frame(
    Country = character(0),
    Median = numeric(0)
  )
  
  for (country_code in unique_countries) {
    subset_data <- final_imputet[final_imputet$country == country_code, variable_name]
    
    # Convert subset_data to numeric
    subset_data <- as.numeric(subset_data)
    
    if (length(subset_data) > 0 && !all(is.na(subset_data))) {
      median_value <- median(subset_data, na.rm = TRUE)
      median_data_all_countries <- rbind(median_data_all_countries, data.frame(Country = country_code, Median = median_value))
    }
  }
  
  if (nrow(median_data_all_countries) > 0) {
    median_plot_all_countries <- ggplot(median_data_all_countries, aes(x = reorder(Country, Median), y = Median)) +
      geom_boxplot() +
      labs(title = paste("Median of", variable_name, "Across All Countries"),
           x = "Countries",
           y = "Median") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
    
    print(median_plot_all_countries)
    
    cat("\f")
  }
}

# Close the PDF
dev.off()

# Display the combined PDF
system(paste(pdf_file, " &", sep = ""))


```

visualize the median for *free_choice, life_satis, financial_satis* across countries. and save it in one PDF
```{r}
# Load required libraries
library(dplyr)
library(ggplot2)
library(tidyr)  

# Select the columns for calculation and visualization
columns_to_analyze <- c("free_choice", "life_satis", "financial_satis")

# Get unique countries in the dataset
unique_countries <- unique(final_imputet$country)

# Create a PDF file to save all country plots
pdf_file <- "country_mean_plots.pdf"
pdf(pdf_file, width = 8, height = 6)

# Loop through each unique country
for (country_code in unique_countries) {
  # Subset data for the current country
  data_to_analyze <- final_imputet %>%
    filter(country == country_code) %>%
    select(all_of(columns_to_analyze))

  # Calculate the mean of selected columns
  mean_values <- data_to_analyze %>%
    summarise(across(everything(), ~ mean(.x, na.rm = TRUE)))

  # Reshape the data for visualization
  mean_data <- mean_values %>%
    pivot_longer(cols = everything(), names_to = "Variable", values_to = "Mean_Value")

  # Map the labels to the mean values
  labels <- c(
    "life_satis" = c("1" = "Dissatisfied", "2" = "2", "3" = "3", "4" = "4", "5" = "5", "6" = "6", "7" = "7", "8" = "8", "9" = "9", "10" = "Satisfied"),
    "free_choice" = c("1" = "None at all", "2" = "2", "3" = "3", "4" = "4", "5" = "5", "6" = "6", "7" = "7", "8" = "8", "9" = "9", "10" = "A great deal")
  )

  mean_data$Variable <- ifelse(mean_data$Variable %in% names(labels), labels[[mean_data$Variable]][as.character(mean_data$Variable)], mean_data$Variable)

  # Create a bar plot to visualize the mean values for the current country
  mean_plot <- ggplot(mean_data, aes(x = Variable, y = Mean_Value)) +
    geom_bar(stat = "identity") +
    labs(title = paste("Mean Values for Selected Columns - Country:", country_code),
         x = "Labels",
         y = "Mean Value") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Print the plot to the PDF file
  print(mean_plot)
}

# Add a page to compare the mean values across countries
# Calculate mean values across all countries
global_mean_values <- final_imputet %>%
  select(all_of(columns_to_analyze)) %>%
  summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Mean_Value")

# Map labels to the global mean values
global_mean_values$Variable <- ifelse(global_mean_values$Variable %in% names(labels), labels[[global_mean_values$Variable]][as.character(global_mean_values$Variable)], global_mean_values$Variable)

# Create a bar plot to visualize the global mean values
global_mean_plot <- ggplot(global_mean_values, aes(x = Variable, y = Mean_Value)) +
  geom_bar(stat = "identity") +
  labs(title = "Mean Values for Selected Columns - Across All Countries",
       x = "Labels",
       y = "Mean Value") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the global mean plot to the PDF file
print(global_mean_plot)

# Close the PDF file
dev.off()

```

correlation with P values without *final_imputet*.
```{r}
# Install and load the required packages
library(Hmisc)
library(openxlsx)

# Create an empty workbook
wb <- createWorkbook()

# List of unique countries
unique_countries <- unique(final_imputet$country)

# Variables of interest
var_of_interest <- c("happiness", "health", "free_choice", "life_satis", "financial_satis",
                     "gen_trust", "age", "gender", "employment", "sign_pet",
                     "join_boycott", "attend_demo", "join_strike", "religiosity")

# Initialize variables to store correlation matrix and p-values for all countries
all_corr_matrix <- NULL
all_p_values <- NULL

# Loop through each country
for (ctry in unique_countries) {
  # Subset data for each country
  subset_data <- subset(final_imputet, country == ctry)
  
  # Generate correlation matrix and p-values
  corr_object <- rcorr(as.matrix(subset_data[, var_of_interest]))
  
  # Extract the correlation matrix and p-values
  corr_matrix <- corr_object$r
  p_values <- corr_object$P
  
  # Create a new sheet in the workbook for each country
  addWorksheet(wb, sheetName = ctry)
  
  # Write the correlation matrix with variable names on the left side
  corr_data <- cbind(variables = rownames(corr_matrix), corr_matrix)
  corr_data[, 2:ncol(corr_data)] <- as.numeric(corr_data[, 2:ncol(corr_data)])
  writeData(wb, sheet = ctry, x = corr_data)
  
  # Calculate the number of rows in the correlation matrix
  num_rows <- nrow(corr_matrix)
  
  # Write p-values in a table below the correlation matrix
  p_data <- cbind(variables = rownames(p_values), p_values)
  p_data[, 2:ncol(p_data)] <- as.numeric(p_data[, 2:ncol(p_data)])
  writeData(wb, sheet = ctry, x = p_data, startRow = num_rows + 3)
  
  # Append the correlation matrix and p-values to the all_corr_matrix and all_p_values variables
  all_corr_matrix <- cbind(all_corr_matrix, corr_matrix)
  all_p_values <- cbind(all_p_values, p_values)
}

# Create a new sheet for the correlation across all countries
addWorksheet(wb, sheetName = "All_Countries_Correlation")

# Calculate the overall correlation matrix and p-values for all countries
overall_corr_matrix <- rcorr(as.matrix(final_imputet[, var_of_interest]))$r
overall_p_values <- rcorr(as.matrix(final_imputet[, var_of_interest]))$P

# Write the overall correlation matrix with variable names on the left side
overall_corr_data <- cbind(variables = rownames(overall_corr_matrix), overall_corr_matrix)
overall_corr_data[, 2:ncol(overall_corr_data)] <- as.numeric(overall_corr_data[, 2:ncol(overall_corr_data)])
writeData(wb, sheet = "All_Countries_Correlation", x = overall_corr_data)

# Calculate the number of rows in the overall correlation matrix
num_rows <- nrow(overall_corr_matrix)

# Write p-values in a table below the overall correlation matrix
overall_p_data <- cbind(variables = rownames(overall_p_values), overall_p_values)
overall_p_data[, 2:ncol(overall_p_data)] <- as.numeric(overall_p_data[, 2:ncol(overall_p_data)])
writeData(wb, sheet = "All_Countries_Correlation", x = overall_p_data, startRow = num_rows + 3)

# Save workbook (you can choose your own file name and path)
saveWorkbook(wb, "Correlation_and_Pvalues_By_Country_and_All_Countries_imputet.xlsx", overwrite = TRUE)

```

correlation with P values without *final_dataset*.
```{r}
# Install and load the required packages
library(Hmisc)
library(openxlsx)

# Create an empty workbook
wb <- createWorkbook()

# List of unique countries
unique_countries <- unique(final_dataset$country)

# Variables of interest
var_of_interest <- c("happiness", "health", "free_choice", "life_satis", "financial_satis",
                     "gen_trust", "age", "gender", "employment", "sign_pet",
                     "join_boycott", "attend_demo", "join_strike", "religiosity")

# Initialize variables to store correlation matrix and p-values for all countries
all_corr_matrix <- NULL
all_p_values <- NULL

# Loop through each country
for (ctry in unique_countries) {
  # Subset data for each country
  subset_data <- subset(final_dataset, country == ctry)
  
  # Generate correlation matrix and p-values
  corr_object <- rcorr(as.matrix(subset_data[, var_of_interest]))
  
  # Extract the correlation matrix and p-values
  corr_matrix <- corr_object$r
  p_values <- corr_object$P
  
  # Create a new sheet in the workbook for each country
  addWorksheet(wb, sheetName = ctry)
  
  # Write the correlation matrix with variable names on the left side
  corr_data <- cbind(variables = rownames(corr_matrix), corr_matrix)
  corr_data[, 2:ncol(corr_data)] <- as.numeric(corr_data[, 2:ncol(corr_data)])
  writeData(wb, sheet = ctry, x = corr_data)
  
  # Calculate the number of rows in the correlation matrix
  num_rows <- nrow(corr_matrix)
  
  # Write p-values in a table below the correlation matrix
  p_data <- cbind(variables = rownames(p_values), p_values)
  p_data[, 2:ncol(p_data)] <- as.numeric(p_data[, 2:ncol(p_data)])
  writeData(wb, sheet = ctry, x = p_data, startRow = num_rows + 3)
  
  # Append the correlation matrix and p-values to the all_corr_matrix and all_p_values variables
  all_corr_matrix <- cbind(all_corr_matrix, corr_matrix)
  all_p_values <- cbind(all_p_values, p_values)
}

# Create a new sheet for the correlation across all countries
addWorksheet(wb, sheetName = "All_Countries_Correlation")

# Calculate the overall correlation matrix and p-values for all countries
overall_corr_matrix <- rcorr(as.matrix(final_dataset[, var_of_interest]))$r
overall_p_values <- rcorr(as.matrix(final_dataset[, var_of_interest]))$P

# Write the overall correlation matrix with variable names on the left side
overall_corr_data <- cbind(variables = rownames(overall_corr_matrix), overall_corr_matrix)
overall_corr_data[, 2:ncol(overall_corr_data)] <- as.numeric(overall_corr_data[, 2:ncol(overall_corr_data)])
writeData(wb, sheet = "All_Countries_Correlation", x = overall_corr_data)

# Calculate the number of rows in the overall correlation matrix
num_rows <- nrow(overall_corr_matrix)

# Write p-values in a table below the overall correlation matrix
overall_p_data <- cbind(variables = rownames(overall_p_values), overall_p_values)
overall_p_data[, 2:ncol(overall_p_data)] <- as.numeric(overall_p_data[, 2:ncol(overall_p_data)])
writeData(wb, sheet = "All_Countries_Correlation", x = overall_p_data, startRow = num_rows + 3)

# Save workbook (you can choose your own file name and path)
saveWorkbook(wb, "Correlation_and_Pvalues_By_Country_and_All_Countries.xlsx", overwrite = TRUE)

```


```{r}
# Load the rjags package
library(rjags)

# Prepare data for JAGS
data_list <- list(
  N = nrow(final_imputet),
  sign_pet = final_imputet$sign_pet,
  join_boycott = final_imputet$join_boycott,
  attend_demo = final_imputet$attend_demo,
  join_strike = final_imputet$join_strike,
  free_choice = final_imputet$free_choice,
  life_satis = final_imputet$life_satis,
  financial_satis = final_imputet$financial_satis,
  happiness = final_imputet$happiness,
  health = final_imputet$health,
  voice_account_score = final_imputet$var,
  gen_trust = final_imputet$gen_trust,
  religiosity = final_imputet$religiosity,
  gender = final_imputet$gender,
  employment = final_imputet$employment,
  country = as.integer(final_imputet$country),
  n_country = length(unique(final_imputet$country))
)

# Model specification with interaction terms
model_string <- "
model {
  for (i in 1:N) {
    sign_pet[i] ~ dnorm(mu_sign[i], tau_sign)
    mu_sign[i] <- alpha_sign[country[i]] + beta_voice[country[i]] * voice_account_score[i] + beta_free_choice * free_choice[i] + beta_voice_free_choice[country[i]] * voice_account_score[i] * free_choice[i]  + beta_happiness * happiness[i] + beta_gen_trust * gen_trust[i] + beta_religiosity * religiosity[i] + beta_gender * gender[i] + beta_employment * employment[i]
  
    join_boycott[i] ~ dnorm(mu_boycott[i], tau_boycott)
    mu_boycott[i] <- alpha_boycott[country[i]] + beta_voice[country[i]] * voice_account_score[i] + beta_life_satis * life_satis[i] + beta_voice_life_satis[country[i]] * voice_account_score[i] * life_satis[i] + beta_health * health[i]
  
    attend_demo[i] ~ dnorm(mu_demo[i], tau_demo)
    mu_demo[i] <- alpha_demo[country[i]] + beta_voice[country[i]] * voice_account_score[i] + beta_financial_satis * financial_satis[i] + beta_voice_financial_satis[country[i]] * voice_account_score[i] * financial_satis[i]
  
    join_strike[i] ~ dnorm(mu_strike[i], tau_strike)
    mu_strike[i] <- alpha_strike[country[i]] + beta_voice[country[i]] * voice_account_score[i] + beta_health * health[i] + beta_voice_health[country[i]] * voice_account_score[i] * health[i]
  }
  
  # Individual-level fixed effects
  beta_free_choice ~ dnorm(0, 0.001)
  beta_happiness ~ dnorm(0, 0.001)
  beta_life_satis ~ dnorm(0, 0.001)
  beta_health ~ dnorm(0, 0.001)
  beta_financial_satis ~ dnorm(0, 0.001)
  beta_gen_trust ~ dnorm(0, 0.001)
  beta_religiosity ~ dnorm(0, 0.001)
  beta_gender ~ dnorm(0, 0.001)
  beta_employment ~ dnorm(0, 0.001)
  
  # Country-level fixed effects and interaction terms
  for (j in 1:n_country) {
    alpha_sign[j] ~ dnorm(0, 0.001)
    alpha_boycott[j] ~ dnorm(0, 0.001)
    alpha_demo[j] ~ dnorm(0, 0.001)
    alpha_strike[j] ~ dnorm(0, 0.001)
    beta_voice[j] ~ dnorm(0, 0.001)
    beta_voice_free_choice[j] ~ dnorm(0, 0.001)
    beta_voice_life_satis[j] ~ dnorm(0, 0.001)
    beta_voice_financial_satis[j] ~ dnorm(0, 0.001)
    beta_voice_health[j] ~ dnorm(0, 0.001)
  }
  
  # Precision parameters
  tau_sign ~ dgamma(0.001, 0.001)
  tau_boycott ~ dgamma(0.001, 0.001)
  tau_demo ~ dgamma(0.001, 0.001)
  tau_strike ~ dgamma(0.001, 0.001)
}
"

# Initialize model
jags_model <- jags.model(textConnection(model_string), data = data_list)

# Burn-in
update(jags_model, 1000)

# Sample from the posterior
samples <- coda.samples(jags_model, variable.names = c("alpha_sign", "alpha_boycott", "alpha_demo", "alpha_strike", "beta_voice", "beta_free_choice", "beta_happiness", "beta_life_satis", "beta_health", "beta_financial_satis", "beta_gen_trust", "beta_religiosity", "beta_gender", "beta_employment", "tau_sign", "tau_boycott", "tau_demo", "tau_strike", "beta_voice_free_choice", "beta_voice_life_satis", "beta_voice_financial_satis", "beta_voice_health"), n.iter = 1000)

# Summary statistics
summary(samples)
```
